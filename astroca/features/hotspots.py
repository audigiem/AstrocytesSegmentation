import math
from typing import List, Dict, Tuple
import numpy as np
import csv
import os


def compute_hot_spots_from_features(features_dict: Dict, params: Dict) -> List[Dict]:
    """
    Identifies hot spots directly from features dictionary based on Euclidean distance
    between centroids of localized events.

    Args:
        features_dict: Dictionary containing event features with keys like event_id and feature values
        params: Dictionary containing parameters for hot spot detection

    Returns:
        List of hot spot groups with temporal analysis
    """
    required_keys = {"features_extraction"}
    if not required_keys.issubset(params.keys()):
        raise ValueError(
            f"Missing required keys in params: {required_keys - set(params.keys())}"
        )

    # Extract parameters
    voxel_size_x = float(params["features_extraction"]["voxel_size_x"])
    voxel_size_y = float(params["features_extraction"]["voxel_size_y"])
    voxel_size_z = float(params["features_extraction"]["voxel_size_z"])
    threshold_hot_spot = float(params["features_extraction"]["threshold_hot_spots"])

    # Extract localized events directly from features dictionary
    localized_data = _extract_localized_events(features_dict)
    if not localized_data:
        raise ValueError("No localized events found in features data")

    # Extract coordinates, labels and time information
    event_data = []
    for event_id, event_features in localized_data.items():
        event_data.append(
            {
                "label": event_id,
                "x": event_features["CentroidX [voxel]"],
                "y": event_features["CentroidY [voxel]"],
                "z": event_features["CentroidZ [voxel]"],
                "t0": event_features["T0 [frame]"],
            }
        )

    # Sort by time for temporal analysis
    event_data.sort(key=lambda x: x["t0"])

    # Extract arrays for processing
    labels = np.array([item["label"] for item in event_data], dtype=np.int32)
    coordinates = np.array(
        [[item["x"], item["y"], item["z"]] for item in event_data], dtype=np.float32
    )
    time_points = np.array([item["t0"] for item in event_data], dtype=np.int32)

    # Scale coordinates by voxel sizes
    voxel_scales = np.array(
        [voxel_size_x, voxel_size_y, voxel_size_z], dtype=np.float32
    )
    scaled_coords = coordinates * voxel_scales

    # Find hot spots using optimized clustering with temporal analysis
    hot_spot_groups = _find_hot_spots_with_temporal_analysis(
        labels, coordinates, scaled_coords, time_points, threshold_hot_spot
    )

    return hot_spot_groups


def _extract_localized_events(features_dict: Dict) -> Dict:
    """
    Extracts localized events from features dictionary.

    Args:
        features_dict: Dictionary with feature data

    Returns:
        Dictionary containing only localized event data
    """
    localized_events = {}

    for event_id, event_features in features_dict.items():
        if event_features["Class"] == "Localized":
            localized_events[event_id] = event_features

    return localized_events


def _find_hot_spots_with_temporal_analysis(
    labels: np.ndarray,
    coordinates: np.ndarray,
    scaled_coords: np.ndarray,
    time_points: np.ndarray,
    threshold: float,
) -> List[Dict]:
    """
    Optimized hot spot detection with temporal interval analysis.

    Args:
        labels: Array of event labels
        coordinates: Original coordinates (unscaled)
        scaled_coords: Coordinates scaled by voxel sizes
        time_points: Array of T0 time points for each event
        threshold: Distance threshold for clustering

    Returns:
        List of hot spot groups with temporal statistics
    """
    n_events = len(labels)
    if n_events == 0:
        return []

    # Track processed events
    processed = np.zeros(n_events, dtype=bool)
    hot_spot_groups = []

    for i in range(n_events):
        if processed[i]:
            continue

        # Calculate distances from current event to all others
        distances = np.linalg.norm(scaled_coords - scaled_coords[i], axis=1)

        # Find events within threshold (including current event)
        within_threshold = distances <= threshold
        group_indices = np.where(within_threshold & ~processed)[0]

        if len(group_indices) > 0:
            # Create hot spot group
            group_labels = labels[group_indices].tolist()
            group_coords = coordinates[group_indices]
            group_times = time_points[group_indices]

            # Calculate temporal statistics
            temporal_stats = _calculate_temporal_intervals(group_times)

            hot_spot_group = {
                "CentroidX [voxel]": float(np.mean(group_coords[:, 0])),
                "CentroidY [voxel]": float(np.mean(group_coords[:, 1])),
                "CentroidZ [voxel]": float(np.mean(group_coords[:, 2])),
                "Nb localized events": len(group_indices),
                "Label(s) event(s)": group_labels,
                "time_points": group_times.tolist(),
                "temporal_span": int(group_times.max() - group_times.min())
                if len(group_times) > 1
                else 0,
                "mean_time_interval": temporal_stats["mean_interval"],
                "median_time_interval": temporal_stats["median_interval"],
                "std_time_interval": temporal_stats["std_interval"],
                "min_time_interval": temporal_stats["min_interval"],
                "max_time_interval": temporal_stats["max_interval"],
            }

            hot_spot_groups.append(hot_spot_group)

            # Mark as processed
            processed[group_indices] = True

    return hot_spot_groups


def _calculate_temporal_intervals(time_points: np.ndarray) -> Dict:
    """
    Calculate temporal interval statistics for events in a hot spot.

    Args:
        time_points: Array of T0 time points

    Returns:
        Dictionary with temporal statistics
    """
    if len(time_points) <= 1:
        return {
            "mean_interval": 0.0,
            "median_interval": 0.0,
            "std_interval": 0.0,
            "min_interval": 0,
            "max_interval": 0,
        }

    # Sort time points
    sorted_times = np.sort(time_points)

    # Calculate intervals between consecutive events
    intervals = np.diff(sorted_times)

    return {
        "mean_interval": float(np.mean(intervals)),
        "median_interval": float(np.median(intervals)),
        "std_interval": float(np.std(intervals)),
        "min_interval": int(intervals.min()),
        "max_interval": int(intervals.max()),
    }


def write_csv_hot_spots(hot_spot_groups: List[Dict], path_output_dir: str) -> None:
    """
    Writes hot spot data to a CSV file with temporal analysis.

    Args:
        hot_spot_groups: List of hot spot groups
        path_output_dir: Output directory path
    """
    if not hot_spot_groups:
        print("No hot spots to write")
        return

    # Ensure output directory exists
    os.makedirs(path_output_dir, exist_ok=True)
    output_file = os.path.join(path_output_dir, "HotSpots.csv")

    try:
        with open(output_file, mode="w", newline="", encoding="utf-8") as csvfile:
            fieldnames = [
                "CentroidX [voxel]",
                "CentroidY [voxel]",
                "CentroidZ [voxel]",
                "Nb localized events [count]",
                "Label(s) event(s) [IDs]",
                "time_points [frames]",
                "temporal_span [frames]",
                "mean_time_interval [frames]",
                "median_time_interval [frames]",
                "std_time_interval [frames]",
                "min_time_interval [frames]",
                "max_time_interval [frames]",
            ]

            writer = csv.DictWriter(csvfile, fieldnames=fieldnames, delimiter=";")
            writer.writeheader()

            for i, group in enumerate(hot_spot_groups, 1):
                # Format labels and time_points as lists for multiple events
                if group["Nb localized events"] > 1:
                    labels_str = (
                        "["
                        + "; ".join(f"{i}" for i in group["Label(s) event(s)"])
                        + "]"
                    )
                    time_points_str = (
                        "[" + "; ".join(f"{i}" for i in group["time_points"]) + "]"
                    )
                else:
                    labels_str = str(group["Label(s) event(s)"][0])
                    time_points_str = str(group["time_points"][0])

                writer.writerow(
                    {
                        "CentroidX [voxel]": group["CentroidX [voxel]"],
                        "CentroidY [voxel]": group["CentroidY [voxel]"],
                        "CentroidZ [voxel]": group["CentroidZ [voxel]"],
                        "Nb localized events [count]": group["Nb localized events"],
                        "Label(s) event(s) [IDs]": labels_str,
                        "time_points [frames]": time_points_str,
                        "temporal_span [frames]": group["temporal_span"],
                        "mean_time_interval [frames]": group["mean_time_interval"],
                        "median_time_interval [frames]": group["median_time_interval"],
                        "std_time_interval [frames]": group["std_time_interval"],
                        "min_time_interval [frames]": group["min_time_interval"],
                        "max_time_interval [frames]": group["max_time_interval"],
                    }
                )

        print(f"Hot spots written to {output_file}")
        print(f"COMPLETED - Found {len(hot_spot_groups)} hot spots")

        # Cr√©er le fichier de documentation
        _create_hotspots_documentation_file(path_output_dir)

    except IOError as e:
        print(f"Error writing hot spots file: {e}")


def _create_hotspots_documentation_file(path_output_dir: str) -> None:
    """
    Creates a documentation file explaining the hot spots CSV columns.

    Args:
        path_output_dir: Output directory path
    """
    doc_path = os.path.join(path_output_dir, "hotspots_columns_documentation.txt")

    documentation = """DOCUMENTATION - FICHIER HOTSPOTS.CSV
====================================

Ce fichier contient l'analyse des hot spots (zones de forte activit√©) identifi√©es par clustering spatial des √©v√©nements localis√©s.

DESCRIPTION DES COLONNES :
-------------------------

CentroidX [voxel] :
- Description : Coordonn√©e X du centro√Øde du hot spot
- Unit√© : voxel (coordonn√©e en voxels)
- Calcul : Moyenne des coordonn√©es X de tous les √©v√©nements du cluster
- Formule : mean(X‚ÇÅ, X‚ÇÇ, ..., X‚Çô) o√π n = nombre d'√©v√©nements dans le hot spot

CentroidY [voxel] :
- Description : Coordonn√©e Y du centro√Øde du hot spot
- Unit√© : voxel (coordonn√©e en voxels)
- Calcul : Moyenne des coordonn√©es Y de tous les √©v√©nements du cluster
- Formule : mean(Y‚ÇÅ, Y‚ÇÇ, ..., Y‚Çô)

CentroidZ [voxel] :
- Description : Coordonn√©e Z du centro√Øde du hot spot
- Unit√© : voxel (coordonn√©e en voxels)
- Calcul : Moyenne des coordonn√©es Z de tous les √©v√©nements du cluster
- Formule : mean(Z‚ÇÅ, Z‚ÇÇ, ..., Z‚Çô)

Nb localized events [count] :
- Description : Nombre d'√©v√©nements localis√©s regroup√©s dans ce hot spot
- Unit√© : count (nombre d'√©v√©nements)
- Calcul : Comptage direct des √©v√©nements dans le cluster spatial
- Valeur minimale : 1 (un hot spot contient au moins un √©v√©nement)

Label(s) event(s) [IDs] :
- Description : Identifiants des √©v√©nements constituant le hot spot
- Unit√© : IDs (identifiants num√©riques)
- Format : [ID1; ID2; ID3] pour plusieurs √©v√©nements, ou ID unique pour un √©v√©nement isol√©
- Calcul : Liste des labels des √©v√©nements dont la distance mutuelle ‚â§ seuil

time_points [frames] :
- Description : Instants temporels (T0) auxquels se produisent les √©v√©nements du hot spot
- Unit√© : frames (num√©ros de frames)
- Format : [T0‚ÇÅ; T0‚ÇÇ; T0‚ÇÉ] pour plusieurs √©v√©nements, ou T0 unique
- Calcul : Extraction directe des valeurs T0 des √©v√©nements du cluster

temporal_span [frames] :
- Description : √âtendue temporelle du hot spot (dur√©e entre premier et dernier √©v√©nement)
- Unit√© : frames (nombre de frames)
- Calcul : max(T0) - min(T0) pour les √©v√©nements du hot spot
- Valeur : 0 pour les hot spots √† √©v√©nement unique

mean_time_interval [frames] :
- Description : Intervalle temporel moyen entre √©v√©nements cons√©cutifs
- Unit√© : frames (nombre de frames)
- Calcul : Moyenne des diff√©rences entre T0 cons√©cutifs tri√©s par ordre temporel
- Valeur : 0.0 pour les hot spots √† √©v√©nement unique

median_time_interval [frames] :
- Description : Intervalle temporel m√©dian entre √©v√©nements cons√©cutifs
- Unit√© : frames (nombre de frames)
- Calcul : M√©diane des diff√©rences entre T0 cons√©cutifs
- Valeur : 0.0 pour les hot spots √† √©v√©nement unique

std_time_interval [frames] :
- Description : √âcart-type des intervalles temporels entre √©v√©nements
- Unit√© : frames (nombre de frames)
- Calcul : √âcart-type des diff√©rences entre T0 cons√©cutifs
- Valeur : 0.0 pour les hot spots √† √©v√©nement unique
- Utilit√© : Indicateur de r√©gularit√© temporelle (faible = r√©gulier, √©lev√© = irr√©gulier)

min_time_interval [frames] :
- Description : Intervalle temporel minimal entre √©v√©nements cons√©cutifs
- Unit√© : frames (nombre de frames)
- Calcul : Minimum des diff√©rences entre T0 cons√©cutifs
- Valeur : 0 pour les hot spots √† √©v√©nement unique

max_time_interval [frames] :
- Description : Intervalle temporel maximal entre √©v√©nements cons√©cutifs
- Unit√© : frames (nombre de frames)
- Calcul : Maximum des diff√©rences entre T0 cons√©cutifs
- Valeur : 0 pour les hot spots √† √©v√©nement unique

M√âTHODE DE D√âTECTION DES HOT SPOTS :
-----------------------------------

1. CLUSTERING SPATIAL :
   - Algorithme : Clustering par seuil de distance euclidienne
   - Crit√®re : Distance 3D ‚â§ threshold_hot_spots (param√®tre configurable)
   - Formule de distance : ‚àö[(X‚ÇÅ-X‚ÇÇ)¬≤√óvoxel_size_x¬≤ + (Y‚ÇÅ-Y‚ÇÇ)¬≤√óvoxel_size_y¬≤ + (Z‚ÇÅ-Z‚ÇÇ)¬≤√óvoxel_size_z¬≤]

2. ANALYSE TEMPORELLE :
   - Tri des √©v√©nements par T0 croissant
   - Calcul des intervalles entre √©v√©nements cons√©cutifs
   - Statistiques temporelles (moyenne, m√©diane, √©cart-type, min, max)

3. CRIT√àRES D'INCLUSION :
   - Tous les √©v√©nements localis√©s sont consid√©r√©s
   - Un √©v√©nement isol√© forme un hot spot de taille 1
   - Pas de seuil minimal sur le nombre d'√©v√©nements

INTERPR√âTATION DES R√âSULTATS :
-----------------------------

- Hot spots de grande taille (Nb events √©lev√©) : Zones d'activit√© intense
- Temporal_span √©lev√© : Activit√© persistante dans le temps
- std_time_interval faible : Activit√© r√©guli√®re/p√©riodique
- std_time_interval √©lev√© : Activit√© en rafales ou irr√©guli√®re
- min_time_interval tr√®s faible : √âv√©nements quasi-simultan√©s possibles

PARAMETRES UTILIS√âS :
--------------------
- threshold_hot_spots : Seuil de distance pour le clustering (en ¬µm)
- voxel_size_x/y/z : Tailles des voxels pour conversion spatiale
- Coordonn√©es en voxels converties en distances physiques pour le clustering

NOTES TECHNIQUES :
-----------------
- Le d√©limiteur du CSV est le point-virgule (;)
- Les coordonn√©es de centro√Ødes restent en voxels pour coh√©rence avec les donn√©es d'entr√©e
- Les distances de clustering sont calcul√©es en microm√®tres
- Algorithme optimis√© pour traiter de grands volumes de donn√©es

G√©n√©r√© automatiquement par le module hotspots.py
"""

    try:
        with open(doc_path, "w", encoding="utf-8") as f:
            f.write(documentation)
        print(f"Documentation hot spots cr√©√©e : {doc_path}")
    except IOError as e:
        print(f"Erreur lors de la cr√©ation de la documentation hot spots : {e}")


def get_hot_spot_statistics(hot_spot_groups: List[Dict]) -> Dict:
    """
    Analyzes hot spot statistics including temporal analysis.

    Returns:
        Dictionary with comprehensive statistics
    """
    if not hot_spot_groups:
        return {"total_hot_spots": 0}

    event_counts = [group["event_count"] for group in hot_spot_groups]
    temporal_spans = [group["temporal_span"] for group in hot_spot_groups]
    mean_intervals = [
        group["mean_time_interval"]
        for group in hot_spot_groups
        if group["mean_time_interval"] > 0
    ]

    stats = {
        "total_hot_spots": len(hot_spot_groups),
        "total_events_in_hot_spots": sum(event_counts),
        "average_events_per_hot_spot": float(np.mean(event_counts)),
        "median_events_per_hot_spot": float(np.median(event_counts)),
        "max_events_per_hot_spot": max(event_counts),
        "min_events_per_hot_spot": min(event_counts),
        "hot_spot_sizes": event_counts,
        "average_temporal_span": float(np.mean(temporal_spans)),
        "median_temporal_span": float(np.median(temporal_spans)),
        "max_temporal_span": max(temporal_spans),
        "min_temporal_span": min(temporal_spans),
    }

    if mean_intervals:
        stats.update(
            {
                "average_mean_time_interval": float(np.mean(mean_intervals)),
                "median_mean_time_interval": float(np.median(mean_intervals)),
                "overall_temporal_regularity": float(np.std(mean_intervals)),
            }
        )

    return stats


def analyze_hot_spot_temporal_patterns(hot_spot_groups: List[Dict]) -> Dict:
    """
    Advanced temporal pattern analysis for hot spots.

    Returns:
        Dictionary with temporal pattern analysis
    """
    if not hot_spot_groups:
        return {}

    patterns = {
        "single_event_spots": 0,
        "regular_intervals": 0,  # CV < 0.5
        "irregular_intervals": 0,  # CV >= 0.5
        "burst_patterns": 0,  # Very short intervals followed by long ones
        "periodic_candidates": [],  # Hot spots with potentially periodic behavior
    }

    for group in hot_spot_groups:
        if group["event_count"] == 1:
            patterns["single_event_spots"] += 1
        elif group["event_count"] > 1:
            # Coefficient of variation for interval regularity
            if group["std_time_interval"] > 0 and group["mean_time_interval"] > 0:
                cv = group["std_time_interval"] / group["mean_time_interval"]
                if cv < 0.5:
                    patterns["regular_intervals"] += 1
                    if group["event_count"] >= 3:  # Minimum for periodicity analysis
                        patterns["periodic_candidates"].append(
                            {
                                "hotspot_id": group["representative_label"],
                                "event_count": group["event_count"],
                                "mean_interval": group["mean_time_interval"],
                                "cv": cv,
                            }
                        )
                else:
                    patterns["irregular_intervals"] += 1

            # Detect burst patterns (mix of very short and long intervals)
            if (
                group["min_time_interval"] <= 2
                and group["max_time_interval"] >= 10
                and group["event_count"] >= 3
            ):
                patterns["burst_patterns"] += 1

    return patterns
